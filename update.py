import yfinance as yf
import feedparser
import datetime
import urllib.parse
import time
import json
import os
import re
# â˜…â˜…â˜… ë²ˆì—­ê¸° ë¼ì´ë¸ŒëŸ¬ë¦¬ (í‚¤ í•„ìš” ì—†ìŒ, ë¬´ì œí•œ) â˜…â˜…â˜…
from deep_translator import GoogleTranslator

# ==========================================
# 1. ì„¤ì • ë° í—¬í¼ í•¨ìˆ˜
# ==========================================
ARCHIVE_FILE = 'news_archive.json'
MAX_ITEMS = 2000

# â˜…â˜…â˜… í…ìŠ¤íŠ¸ ë²ˆì—­ í•¨ìˆ˜ â˜…â˜…â˜…
def translate_text(text):
    if not text: return ""
    try:
        # ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­ (ê³ ìœ ëª…ì‚¬ëŠ” êµ¬ê¸€ ë²ˆì—­ê¸° ë¡œì§ì„ ë”°ë¦„)
        translated = GoogleTranslator(source='auto', target='ko').translate(text)
        return translated
    except Exception as e:
        print(f"âŒ Translation Error: {e}")
        return text # ì—ëŸ¬ë‚˜ë©´ ì›ë¬¸ ê·¸ëŒ€ë¡œ ë¦¬í„´

def clean_html(raw_html):
    cleanr = re.compile('<.*?>')
    text = re.sub(cleanr, '', raw_html)
    return text.replace('&nbsp;', ' ').strip()

def make_sparkline_url(data_list, color):
    if not data_list or len(data_list) < 2: return ""
    subset = data_list[-30:]
    data_str = ",".join([f"{x:.2f}" for x in subset])
    chart_config = f"{{type:'sparkline',data:{{datasets:[{{data:[{data_str}],borderColor:'{color}',borderWidth:2,fill:false,pointRadius:0}}]}}}}"
    return "https://quickchart.io/chart?c=" + urllib.parse.quote(chart_config)

def get_metric_data(ticker, color):
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="1mo")
        if hist.empty: return "N/A", "0.00%", ""
        current = hist['Close'].iloc[-1]
        prev = hist['Close'].iloc[-2]
        change = current - prev
        change_pct = (change / prev) * 100
        sign = "+" if change >= 0 else ""
        css_class = "text-red" if change >= 0 else "text-blue"
        val_str = f"{current:,.2f}"
        if ticker == "KRW=X": val_str += " ì›"
        change_str = f"<span class='{css_class}'>{sign}{change:.2f} ({sign}{change_pct:.2f}%)</span>"
        chart_url = make_sparkline_url(hist['Close'].tolist(), color)
        return val_str, change_str, chart_url
    except: return "Error", "-", ""

def load_archive():
    if os.path.exists(ARCHIVE_FILE):
        with open(ARCHIVE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def save_archive(data):
    data.sort(key=lambda x: x['date'], reverse=True)
    if len(data) > MAX_ITEMS: data = data[:MAX_ITEMS]
    with open(ARCHIVE_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ==========================================
# 2. ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘
# ==========================================
print("1. ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘...")
kospi_val, kospi_chg, kospi_chart = get_metric_data("^KS11", "red")
sp500_val, sp500_chg, sp500_chart = get_metric_data("^GSPC", "red")
usdkrw_val, usdkrw_chg, usdkrw_chart = get_metric_data("KRW=X", "green")

korea_tickers = [
    ('005930.KS', 'ì‚¼ì„±ì „ì', '005930'), ('000660.KS', 'SKí•˜ì´ë‹‰ìŠ¤', '000660'),
    ('373220.KS', 'LGì—ë„ˆì§€ì†”ë£¨ì…˜', '373220'), ('207940.KS', 'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤', '207940'),
    ('005380.KS', 'í˜„ëŒ€ì°¨', '005380'), ('005490.KS', 'POSCOí™€ë”©ìŠ¤', '005490'),
    ('000270.KS', 'ê¸°ì•„', '000270'), ('035420.KS', 'NAVER', '035420')
]
korea_table_html = "<table class='stock-table'><thead><tr><th>ì¢…ëª©ëª…</th><th>í˜„ì¬ê°€</th><th>ë“±ë½ë¥ </th><th>ì¶”ì„¸(1ë‹¬)</th></tr></thead><tbody>"
for code, name, naver_code in korea_tickers:
    try:
        stock = yf.Ticker(code)
        hist = stock.history(period="1mo")
        if not hist.empty:
            curr = hist['Close'].iloc[-1]
            prev = hist['Close'].iloc[-2]
            pct = ((curr - prev) / prev) * 100
            if pct > 0: color_cls, sign, line_color = "bg-red-light text-red", "+", "red"
            elif pct < 0: color_cls, sign, line_color = "bg-blue-light text-blue", "", "blue"
            else: color_cls, sign, line_color = "text-gray", "", "gray"
            chart = make_sparkline_url(hist['Close'].tolist(), line_color)
            link_url = f"https://finance.naver.com/item/main.naver?code={naver_code}"
            korea_table_html += f"<tr onclick=\"window.open('{link_url}', '_blank')\" style=\"cursor:pointer;\"><td><span class='stock-name'>{name} ğŸ”—</span><span class='stock-code'>{code}</span></td><td class='stock-price'>{curr:,.0f}ì›</td><td><span class='{color_cls}'>{sign}{pct:.2f}%</span></td><td><img src='{chart}' style='height:30px; width:80px;'></td></tr>"
    except: pass
korea_table_html += "</tbody></table>"

# ==========================================
# 3. ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë²ˆì—­
# ==========================================
print("2. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë° ë²ˆì—­ (Deep Translator)...")
archive = load_archive()
existing_links = set(item['link'] for item in archive)

# [ê²½ì œ ë‰´ìŠ¤] - ì•„ì¹¨ ë¸Œë¦¬í•‘ìš©
rss_economy = [{"url": "https://news.google.com/rss/search?q=stock+market+economy+korea+usa&hl=ko&gl=KR&ceid=KR:ko", "title": "ğŸ“ˆ êµ­ë‚´ì™¸ ì¦ì‹œ", "cat": "economy"}]

# [íœ´ë¨¸ë…¸ì´ë“œ/ë¡œë´‡ ì¼ë°˜ ë‰´ìŠ¤] - ìš”ì²­í•˜ì‹  ì˜ë¬¸ ì‚¬ì´íŠ¸ ì™„ë²½ í¬í•¨
rss_humanoid = [
    {"url": "https://news.google.com/rss/search?q=humanoid+robot+(startup+OR+unveiled+OR+prototype+OR+new+model)+-vacuum&hl=ko&gl=KR&ceid=KR:ko", "title": "Google News", "cat": "humanoid"},
    {"url": "https://techxplore.com/rss-feed/robotics-news/", "title": "Tech Xplore", "cat": "humanoid"},
    {"url": "https://spectrum.ieee.org/feeds/topic/robotics.rss", "title": "IEEE Spectrum", "cat": "humanoid"},
    {"url": "https://www.therobotreport.com/feed/", "title": "The Robot Report", "cat": "humanoid"},
    {"url": "http://www.irobotnews.com/rss/all.xml", "title": "ë¡œë´‡ì‹ ë¬¸", "cat": "humanoid"},
    {"url": "https://humanoidroboticstechnology.com/feed/", "title": "Humanoid Tech Blog", "cat": "humanoid"}
]

# [ë¡œë´‡ í•¸ë“œ/ê·¸ë¦¬í¼ ë‰´ìŠ¤]
rss_hand = [
    {"url": "https://news.google.com/rss/search?q=robot+hand+gripper+dexterous+manipulation+tactile+sensor+-vacuum&hl=ko&gl=KR&ceid=KR:ko", "title": "Google News", "cat": "hand"}
]

# â˜…â˜…â˜… [ìˆ˜ì •ë¨] ê²½ì œ ë‰´ìŠ¤ë„ ë²ˆì—­ ì²˜ë¦¬ â˜…â˜…â˜…
economy_news_latest = []
print("   >> Processing Economy News...")
for src in rss_economy:
    try:
        feed = feedparser.parse(src["url"], agent="Mozilla/5.0")
        for entry in feed.entries[:4]:
            # ì œëª© ë²ˆì—­!
            entry.title = translate_text(entry.title)
            economy_news_latest.append(entry)
            time.sleep(0.5) # ì§§ì€ ëŒ€ê¸°
    except: pass

today = datetime.datetime.now()
new_items_count = 0

print("   >> Processing Robot News...")
for src in rss_humanoid + rss_hand:
    try:
        feed = feedparser.parse(src["url"], agent="Mozilla/5.0")
        for entry in feed.entries:
            link = entry.link
            if link in existing_links: continue
            
            pub_dt = today
            if hasattr(entry, 'published_parsed') and entry.published_parsed:
                pub_dt = datetime.datetime.fromtimestamp(time.mktime(entry.published_parsed))
            elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                pub_dt = datetime.datetime.fromtimestamp(time.mktime(entry.updated_parsed))
            
            if (today - pub_dt).days > 7: continue

            print(f"Processing: {entry.title}...")
            raw_snippet = clean_html(entry.get('description', entry.get('summary', '')))
            
            # â˜…â˜…â˜… ì œëª©ê³¼ ìš”ì•½ë¬¸ ë²ˆì—­ â˜…â˜…â˜…
            title_ko = translate_text(entry.title)
            # ë‚´ìš©ì€ ë„ˆë¬´ ê¸¸ë©´ 500ìë§Œ ì˜ë¼ì„œ ë²ˆì—­
            summary_ko = translate_text(raw_snippet[:500]) 
            
            time.sleep(1) 

            news_item = {
                "title": title_ko,
                "original_title": entry.title,
                "link": link,
                "date": pub_dt.strftime("%Y-%m-%d %H:%M"),
                "source": src['title'],
                "category": src['cat'],
                "summary": summary_ko
            }
            archive.append(news_item)
            existing_links.add(link)
            new_items_count += 1
            
            # 20ê°œ ì œí•œ
            if new_items_count >= 20:
                print("ğŸ›‘ 20ê°œ ì²˜ë¦¬ ì™„ë£Œ. ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
        
        if new_items_count >= 20: break

    except Exception as e:
        print(f"RSS Error: {e}")

save_archive(archive)
print(f"New items: {new_items_count}")

# ==========================================
# 4. HTML ìƒì„±
# ==========================================
print("3. HTML ìƒì„±...")
utc_now = datetime.datetime.now(datetime.timezone.utc)
kst_now = utc_now + datetime.timedelta(hours=9)
now_str = kst_now.strftime("%Y-%m-%d %H:%M:%S (KST)")

# ë©”ì¸ í˜ì´ì§€ (index.html)
def generate_simple_list(items):
    html = ""
    for item in items[:4]:
        # ì—¬ê¸°ì„œëŠ” ì´ë¯¸ ë²ˆì—­ëœ titleì„ ì‚¬ìš©í•˜ê±°ë‚˜, economy_news_latestì˜ ê²½ìš° ìœ„ì—ì„œ ë²ˆì—­í•´ë‘” title ì‚¬ìš©
        title = item.get('title') if isinstance(item, dict) else item.title
        link = item.get('link') if isinstance(item, dict) else item.link
        html += f"<li class='news-item'><a href='{link}' target='_blank'>{title}</a></li>"
    return html

latest_humanoid = [x for x in archive if x['category'] == 'humanoid']
latest_hand = [x for x in archive if x['category'] == 'hand']

main_news_html = ""
# ê²½ì œ ë‰´ìŠ¤ë„ ì´ì œ í•œê¸€ë¡œ ë‚˜ì˜µë‹ˆë‹¤
if economy_news_latest:
    main_news_html += f"<div class='news-category'><h4><span class='badge'>ğŸ“ˆ ì¦ì‹œ/ê²½ì œ</span></h4><ul class='news-list'>{generate_simple_list(economy_news_latest)}</ul></div>"
if latest_humanoid:
    main_news_html += f"<div class='news-category'><h4><span class='badge'>ğŸ¤– íœ´ë¨¸ë…¸ì´ë“œ</span></h4><ul class='news-list'>{generate_simple_list(latest_humanoid)}</ul></div>"
if latest_hand:
    main_news_html += f"<div class='news-category'><h4><span class='badge'>ğŸ¦¾ í•¸ë“œ/ê·¸ë¦¬í¼</span></h4><ul class='news-list'>{generate_simple_list(latest_hand)}</ul></div>"

with open('template.html', 'r', encoding='utf-8') as f:
    template = f.read()
output_main = template.replace('{{LAST_UPDATED}}', now_str)
output_main = output_main.replace('{{KOSPI_VAL}}', kospi_val).replace('{{KOSPI_CHANGE}}', kospi_chg).replace('{{KOSPI_CHART}}', kospi_chart)
output_main = output_main.replace('{{SP500_VAL}}', sp500_val).replace('{{SP500_CHANGE}}', sp500_chg).replace('{{SP500_CHART}}', sp500_chart)
output_main = output_main.replace('{{USDKRW_VAL}}', usdkrw_val).replace('{{USDKRW_CHANGE}}', usdkrw_chg).replace('{{USDKRW_CHART}}', usdkrw_chart)
output_main = output_main.replace('{{KOREA_MARKET_HTML}}', korea_table_html)
output_main = output_main.replace('{{NEWS_CONTENT}}', main_news_html)

with open('index.html', 'w', encoding='utf-8') as f:
    f.write(output_main)

# ë‰´ìŠ¤ í˜ì´ì§€ (news.html)
def generate_card_list(items):
    html = ""
    for item in items:
        summary_html = f"<div class='news-summary' style='color:#555; font-size:0.95rem; margin-top:8px; line-height:1.6;'>ğŸ’¡ {item.get('summary', '')}</div>" if item.get('summary') else ""
        original_title = item.get('original_title', '').replace("'", "&#39;")
        html += f"""
        <div class='news-card'>
            <a href='{item['link']}' target='_blank' class='news-title'>{item['title']}</a>
            <div class='hidden-keywords' style='display:none;'>{original_title}</div>
            {summary_html}
            <div class='news-meta' style='margin-top:10px;'>
                <span class='source-tag'>{item['source']}</span>
                <span class='date-tag'>{item['date'][:10]}</span>
            </div>
        </div>
        """
    return html

with open('news_template.html', 'r', encoding='utf-8') as f:
    news_template = f.read()

output_news = news_template.replace('{{LAST_UPDATED}}', now_str)
output_news = output_news.replace('{{HUMANOID_NEWS_FULL}}', generate_card_list(latest_humanoid))
output_news = output_news.replace('{{HAND_NEWS_FULL}}', generate_card_list(latest_hand))

with open('news.html', 'w', encoding='utf-8') as f:
    f.write(output_news)

print("ì™„ë£Œ!")
