import yfinance as yf
import feedparser
import datetime
import urllib.parse
import time
import json
import os
import re
import google.generativeai as genai

# ==========================================
# 1. ì„¤ì • ë° í—¬í¼ í•¨ìˆ˜
# ==========================================
ARCHIVE_FILE = 'news_archive.json'
MAX_ITEMS = 2000

# [ë””ë²„ê¹…] API í‚¤ í™•ì¸
GEMINI_KEY = os.environ.get('GEMINI_API_KEY')
if GEMINI_KEY:
    print(f"âœ… DEBUG: GEMINI_API_KEY ê°ì§€ë¨")
    genai.configure(api_key=GEMINI_KEY)
else:
    print("âŒ DEBUG: GEMINI_API_KEY ì—†ìŒ!")

# ëª¨ë¸ ê°€ì ¸ì˜¤ê¸° (1.5 Flash -> Pro ìˆœì„œë¡œ ì‹œë„)
def get_ai_model():
    # 1ìˆœìœ„: 1.5 Flash (ë¹ ë¦„)
    try:
        return genai.GenerativeModel('gemini-1.5-flash')
    except:
        pass
    # 2ìˆœìœ„: Pro (ì•ˆì •ì )
    try:
        return genai.GenerativeModel('gemini-pro')
    except:
        return None

MODEL_INSTANCE = None
if GEMINI_KEY:
    MODEL_INSTANCE = get_ai_model()

# â˜…â˜…â˜… ë¬¸ë²• ì˜¤ë¥˜ ìˆ˜ì •ë¨ (global ì„ ì–¸ ìœ„ì¹˜ ì´ë™) â˜…â˜…â˜…
def process_news_with_ai(title, snippet):
    # í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ì „ì—­ ë³€ìˆ˜ë¥¼ ë°”ê¾¸ë ¤ë©´ ë§¨ ìœ„ì— ì„ ì–¸í•´ì•¼ í•¨
    global MODEL_INSTANCE
    
    fallback_summary = snippet[:300] + ("..." if len(snippet) > 300 else "")
    
    if not MODEL_INSTANCE:
        return title, fallback_summary
    
    # ì¬ì‹œë„ ë¡œì§
    max_retries = 3
    for attempt in range(max_retries):
        try:
            # í”„ë¡¬í”„íŠ¸: JSON ëŒ€ì‹  íŠ¹ìˆ˜ êµ¬ë¶„ì(|||)ë¥¼ ì‚¬ìš©í•´ë‹¬ë¼ê³  ìš”ì²­
            prompt = f"""
            Role: Professional Tech Reporter (Korea).
            Task: Translate title and summarize content into Korean.

            Format your response exactly like this:
            KOREAN_TITLE ||| KOREAN_SUMMARY

            Rules:
            1. Title: Natural Korean translation.
            2. Summary: 2-3 sentences in Korean. Noun-ending style (~í•¨).
            3. Do NOT output markdown, JSON, or any other text. Just the formatted string.

            Input Title: {title}
            Input Snippet: {snippet}
            """
            
            # JSON ëª¨ë“œ ë„ê³  ì¼ë°˜ í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ ìš”ì²­
            response = MODEL_INSTANCE.generate_content(prompt)
            result_text = response.text.strip()
            
            # êµ¬ë¶„ì(|||)ë¡œ ë‚˜ëˆ„ê¸°
            if "|||" in result_text:
                parts = result_text.split("|||")
                title_ko = parts[0].strip()
                summary_ko = parts[1].strip()
                return title_ko, summary_ko
            else:
                return title, result_text
            
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "quota" in error_msg.lower():
                print(f"âš ï¸ Quota Limit! Waiting 60s... (Attempt {attempt+1})")
                time.sleep(60)
                continue
            elif "404" in error_msg:
                 # ëª¨ë¸ ëª» ì°¾ìœ¼ë©´ gemini-proë¡œ êµì²´í•´ì„œ ì¬ì‹œë„
                print("âš ï¸ Model not found. Switching to gemini-pro...")
                MODEL_INSTANCE = genai.GenerativeModel('gemini-pro')
                continue
            else:
                print(f"âŒ AI Error: {error_msg}")
                return title, fallback_summary
    
    return title, fallback_summary

def clean_html(raw_html):
    cleanr = re.compile('<.*?>')
    text = re.sub(cleanr, '', raw_html)
    return text.replace('&nbsp;', ' ').strip()

def make_sparkline_url(data_list, color):
    if not data_list or len(data_list) < 2: return ""
    subset = data_list[-30:]
    data_str = ",".join([f"{x:.2f}" for x in subset])
    chart_config = f"{{type:'sparkline',data:{{datasets:[{{data:[{data_str}],borderColor:'{color}',borderWidth:2,fill:false,pointRadius:0}}]}}}}"
    return "https://quickchart.io/chart?c=" + urllib.parse.quote(chart_config)

def get_metric_data(ticker, color):
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(period="1mo")
        if hist.empty: return "N/A", "0.00%", ""
        current = hist['Close'].iloc[-1]
        prev = hist['Close'].iloc[-2]
        change = current - prev
        change_pct = (change / prev) * 100
        sign = "+" if change >= 0 else ""
        css_class = "text-red" if change >= 0 else "text-blue"
        val_str = f"{current:,.2f}"
        if ticker == "KRW=X": val_str += " ì›"
        change_str = f"<span class='{css_class}'>{sign}{change:.2f} ({sign}{change_pct:.2f}%)</span>"
        chart_url = make_sparkline_url(hist['Close'].tolist(), color)
        return val_str, change_str, chart_url
    except: return "Error", "-", ""

def load_archive():
    if os.path.exists(ARCHIVE_FILE):
        with open(ARCHIVE_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return []

def save_archive(data):
    data.sort(key=lambda x: x['date'], reverse=True)
    if len(data) > MAX_ITEMS: data = data[:MAX_ITEMS]
    with open(ARCHIVE_FILE, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# ==========================================
# 2. ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘
# ==========================================
print("1. ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘...")
kospi_val, kospi_chg, kospi_chart = get_metric_data("^KS11", "red")
sp500_val, sp500_chg, sp500_chart = get_metric_data("^GSPC", "red")
usdkrw_val, usdkrw_chg, usdkrw_chart = get_metric_data("KRW=X", "green")

korea_tickers = [
    ('005930.KS', 'ì‚¼ì„±ì „ì', '005930'), ('000660.KS', 'SKí•˜ì´ë‹‰ìŠ¤', '000660'),
    ('373220.KS', 'LGì—ë„ˆì§€ì†”ë£¨ì…˜', '373220'), ('207940.KS', 'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤', '207940'),
    ('005380.KS', 'í˜„ëŒ€ì°¨', '005380'), ('005490.KS', 'POSCOí™€ë”©ìŠ¤', '005490'),
    ('000270.KS', 'ê¸°ì•„', '000270'), ('035420.KS', 'NAVER', '035420')
]
korea_table_html = "<table class='stock-table'><thead><tr><th>ì¢…ëª©ëª…</th><th>í˜„ì¬ê°€</th><th>ë“±ë½ë¥ </th><th>ì¶”ì„¸(1ë‹¬)</th></tr></thead><tbody>"
for code, name, naver_code in korea_tickers:
    try:
        stock = yf.Ticker(code)
        hist = stock.history(period="1mo")
        if not hist.empty:
            curr = hist['Close'].iloc[-1]
            prev = hist['Close'].iloc[-2]
            pct = ((curr - prev) / prev) * 100
            if pct > 0: color_cls, sign, line_color = "bg-red-light text-red", "+", "red"
            elif pct < 0: color_cls, sign, line_color = "bg-blue-light text-blue", "", "blue"
            else: color_cls, sign, line_color = "text-gray", "", "gray"
            chart = make_sparkline_url(hist['Close'].tolist(), line_color)
            link_url = f"https://finance.naver.com/item/main.naver?code={naver_code}"
            korea_table_html += f"<tr onclick=\"window.open('{link_url}', '_blank')\" style=\"cursor:pointer;\"><td><span class='stock-name'>{name} ğŸ”—</span><span class='stock-code'>{code}</span></td><td class='stock-price'>{curr:,.0f}ì›</td><td><span class='{color_cls}'>{sign}{pct:.2f}%</span></td><td><img src='{chart}' style='height:30px; width:80px;'></td></tr>"
    except: pass
korea_table_html += "</tbody></table>"

# ==========================================
# 3. ë‰´ìŠ¤ ìˆ˜ì§‘ ë° AI ì²˜ë¦¬
# ==========================================
print("2. ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ë° AI ì²˜ë¦¬...")
archive = load_archive()
existing_links = set(item['link'] for item in archive)

rss_economy = [{"url": "https://news.google.com/rss/search?q=stock+market+economy+korea+usa&hl=ko&gl=KR&ceid=KR:ko", "title": "ğŸ“ˆ êµ­ë‚´ì™¸ ì¦ì‹œ", "cat": "economy"}]
rss_humanoid = [
    {"url": "https://news.google.com/rss/search?q=humanoid+robot+(startup+OR+unveiled+OR+prototype+OR+new+model)+-vacuum&hl=ko&gl=KR&ceid=KR:ko", "title": "Google News", "cat": "humanoid"},
    {"url": "https://humanoidroboticstechnology.com/feed/", "title": "Humanoid Tech Blog", "cat": "humanoid"}
]
rss_hand = [
    {"url": "https://news.google.com/rss/search?q=robot+hand+gripper+dexterous+manipulation+tactile+sensor+-vacuum&hl=ko&gl=KR&ceid=KR:ko", "title": "Google News", "cat": "hand"}
]

economy_news_latest = []
for src in rss_economy:
    try:
        feed = feedparser.parse(src["url"], agent="Mozilla/5.0")
        for entry in feed.entries[:4]:
            economy_news_latest.append(entry)
    except: pass

today = datetime.datetime.now()
new_items_count = 0

for src in rss_humanoid + rss_hand:
    try:
        feed = feedparser.parse(src["url"], agent="Mozilla/5.0")
        for entry in feed.entries:
            link = entry.link
            if link in existing_links: continue
            
            pub_dt = today
            if hasattr(entry, 'published_parsed') and entry.published_parsed:
                pub_dt = datetime.datetime.fromtimestamp(time.mktime(entry.published_parsed))
            elif hasattr(entry, 'updated_parsed') and entry.updated_parsed:
                pub_dt = datetime.datetime.fromtimestamp(time.mktime(entry.updated_parsed))
            
            if (today - pub_dt).days > 7: continue

            print(f"AI Processing: {entry.title}...")
            raw_snippet = clean_html(entry.get('description', entry.get('summary', '')))
            
            # AI ì²˜ë¦¬
            title_ko, summary_ko = process_news_with_ai(entry.title, raw_snippet)
            
            # 10ì´ˆ ëŒ€ê¸°
            print("Cooling down (10s)...")
            time.sleep(10) 

            news_item = {
                "title": title_ko,
                "original_title": entry.title,
                "link": link,
                "date": pub_dt.strftime("%Y-%m-%d %H:%M"),
                "source": src['title'],
                "category": src['cat'],
                "summary": summary_ko
            }
            archive.append(news_item)
            existing_links.add(link)
            new_items_count += 1
            
            if new_items_count >= 15:
                print("âš ï¸ ì•ˆì „ì„ ìœ„í•´ ì´ë²ˆ ì‹¤í–‰ì€ 15ê°œê¹Œì§€ë§Œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
                break
        
        if new_items_count >= 15: break

    except Exception as e:
        print(f"RSS Error: {e}")

save_archive(archive)
print(f"New items: {new_items_count}")

# ==========================================
# 4. HTML ìƒì„±
# ==========================================
print("3. HTML ìƒì„±...")
utc_now = datetime.datetime.now(datetime.timezone.utc)
kst_now = utc_now + datetime.timedelta(hours=9)
now_str = kst_now.strftime("%Y-%m-%d %H:%M:%S (KST)")

# ë©”ì¸ í˜ì´ì§€ (index.html)
def generate_simple_list(items):
    html = ""
    for item in items[:4]:
        title = item.get('title') if isinstance(item, dict) else item.title
        link = item.get('link') if isinstance(item, dict) else item.link
        html += f"<li class='news-item'><a href='{link}' target='_blank'>{title}</a></li>"
    return html

latest_humanoid = [x for x in archive if x['category'] == 'humanoid']
latest_hand = [x for x in archive if x['category'] == 'hand']

main_news_html = ""
if economy_news_latest:
    main_news_html += f"<div class='news-category'><h4><span class='badge'>ğŸ“ˆ ì¦ì‹œ/ê²½ì œ</span></h4><ul class='news-list'>{generate_simple_list(economy_news_latest)}</ul></div>"
if latest_humanoid:
    main_news_html += f"<div class='news-category'><h4><span class='badge'>ğŸ¤– íœ´ë¨¸ë…¸ì´ë“œ</span></h4><ul class='news-list'>{generate_simple_list(latest_humanoid)}</ul></div>"
if latest_hand:
    main_news_html += f"<div class='news-category'><h4><span class='badge'>ğŸ¦¾ í•¸ë“œ/ê·¸ë¦¬í¼</span></h4><ul class='news-list'>{generate_simple_list(latest_hand)}</ul></div>"

with open('template.html', 'r', encoding='utf-8') as f:
    template = f.read()
output_main = template.replace('{{LAST_UPDATED}}', now_str)
output_main = output_main.replace('{{KOSPI_VAL}}', kospi_val).replace('{{KOSPI_CHANGE}}', kospi_chg).replace('{{KOSPI_CHART}}', kospi_chart)
output_main = output_main.replace('{{SP500_VAL}}', sp500_val).replace('{{SP500_CHANGE}}', sp500_chg).replace('{{SP500_CHART}}', sp500_chart)
output_main = output_main.replace('{{USDKRW_VAL}}', usdkrw_val).replace('{{USDKRW_CHANGE}}', usdkrw_chg).replace('{{USDKRW_CHART}}', usdkrw_chart)
output_main = output_main.replace('{{KOREA_MARKET_HTML}}', korea_table_html)
output_main = output_main.replace('{{NEWS_CONTENT}}', main_news_html)

with open('index.html', 'w', encoding='utf-8') as f:
    f.write(output_main)

# ë‰´ìŠ¤ í˜ì´ì§€ (news.html)
def generate_card_list(items):
    html = ""
    for item in items:
        summary_html = f"<div class='news-summary' style='color:#555; font-size:0.95rem; margin-top:8px; line-height:1.6;'>ğŸ’¡ {item.get('summary', '')}</div>" if item.get('summary') else ""
        original_title = item.get('original_title', '').replace("'", "&#39;")
        html += f"""
        <div class='news-card'>
            <a href='{item['link']}' target='_blank' class='news-title'>{item['title']}</a>
            <div class='hidden-keywords' style='display:none;'>{original_title}</div>
            {summary_html}
            <div class='news-meta' style='margin-top:10px;'>
                <span class='source-tag'>{item['source']}</span>
                <span class='date-tag'>{item['date'][:10]}</span>
            </div>
        </div>
        """
    return html

with open('news_template.html', 'r', encoding='utf-8') as f:
    news_template = f.read()

output_news = news_template.replace('{{LAST_UPDATED}}', now_str)
output_news = output_news.replace('{{HUMANOID_NEWS_FULL}}', generate_card_list(latest_humanoid))
output_news = output_news.replace('{{HAND_NEWS_FULL}}', generate_card_list(latest_hand))

with open('news.html', 'w', encoding='utf-8') as f:
    f.write(output_news)

print("ì™„ë£Œ!")
