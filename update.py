import yfinance as yf
import feedparser
import datetime
import re
import time
import urllib.parse

# ì°¨íŠ¸ ìƒì„±ì„ ìœ„í•œ í•¨ìˆ˜ (QuickChart ì‚¬ìš©)
def make_sparkline_url(data_list, color='blue'):
    if not data_list:
        return ""
    # ë°ì´í„°ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ URLì´ ê¸¸ì–´ì§€ë¯€ë¡œ ìµœê·¼ 30ê°œë§Œ ì‚¬ìš©
    data_str = ",".join([f"{x:.2f}" for x in data_list[-30:]])
    
    # QuickChart API URL ìƒì„± (ë°°ê²½ íˆ¬ëª…, ì„  ê·¸ë˜í”„, í¬ì¸íŠ¸ ì—†ìŒ)
    chart_config = f"""
    {{
        type: 'sparkline',
        data: {{
            datasets: [{{
                data: [{data_str}],
                borderColor: '{color}',
                borderWidth: 2,
                fill: false,
                pointRadius: 0
            }}]
        }}
    }}
    """
    base_url = "https://quickchart.io/chart?c="
    return base_url + urllib.parse.quote(chart_config)

def get_market_data(ticker, color='rgba(0, 116, 217, 1)'):
    try:
        stock = yf.Ticker(ticker)
        # 1ë‹¬ì¹˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ê·¸ë˜í”„ìš©)
        hist = stock.history(period="1mo")
        if not hist.empty:
            current_price = hist['Close'].iloc[-1]
            price_list = hist['Close'].tolist()
            chart_url = make_sparkline_url(price_list, color)
            return current_price, chart_url
        return None, None
    except Exception as e:
        print(f"Error fetching {ticker}: {e}")
        return None, None

# 1. ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ê°€ê²© ë° ì°¨íŠ¸ URL)
print("1. Fetching Market Data...")
# KOSPI (ë¹¨ê°„ìƒ‰ ê³„ì—´), S&P500 (íŒŒë€ìƒ‰ ê³„ì—´), í™˜ìœ¨ (ì´ˆë¡ìƒ‰ ê³„ì—´)
kospi_val, kospi_chart = get_market_data("^KS11", "red")
sp500_val, sp500_chart = get_market_data("^GSPC", "blue")
usdkrw_val, usdkrw_chart = get_market_data("KRW=X", "green")

# 2. ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (RSS)
print("2. Fetching News...")
rss_urls = [
    ("https://news.google.com/rss/search?q=stock+market+korea+headline&hl=ko&gl=KR&ceid=KR:ko", "ğŸ“ˆ ì¦ì‹œ ì£¼ìš” ë‰´ìŠ¤"),
    ("https://news.google.com/rss/search?q=robot+technology+industry+korea&hl=ko&gl=KR&ceid=KR:ko", "ğŸ¤– ë¡œë´‡/ê¸°ìˆ  ë‰´ìŠ¤"),
    ("https://news.google.com/rss/search?q=robot+gripper+hand+technology&hl=ko&gl=KR&ceid=KR:ko", "ğŸ¦¾ ë¡œë´‡ í•¸ë“œ & ê·¸ë¦¬í¼ ê¸°ìˆ ")
]

news_html = ""
for url, title in rss_urls:
    try:
        feed = feedparser.parse(url)
        news_html += f"<div class='news-group'><h4>{title}</h4><ul>"
        # ë‰´ìŠ¤ í•­ëª©ì´ ì—†ìœ¼ë©´ ë©”ì‹œì§€ í‘œì‹œ
        if not feed.entries:
             news_html += "<li class='news-item'>ìµœê·¼ ê´€ë ¨ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.</li>"
        else:
            for entry in feed.entries[:4]: # 4ê°œì”© ê°€ì ¸ì˜¤ê¸°
                pub_date = entry.published_parsed
                date_str = time.strftime("%m-%d %H:%M", pub_date) if pub_date else ""
                news_html += f"<li class='news-item'><a href='{entry.link}' target='_blank'>{entry.title}</a> <span class='news-date'>({date_str})</span></li>"
        news_html += "</ul></div>"
    except Exception as e:
        print(f"Error fetching news {url}: {e}")

# 3. HTML íŒŒì¼ ì—…ë°ì´íŠ¸
html_file = 'index.html'
with open(html_file, 'r', encoding='utf-8') as f:
    content = f.read()

# ë‚ ì§œ
now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")

# ê°’ êµì²´ ë¡œì§
if kospi_val:
    content = re.sub(r'<p id="kospi-val">.*?</p>', f'<p id="kospi-val">{kospi_val:,.2f}</p>', content)
    content = re.sub(r'<img id="kospi-chart" class="chart-img" src=".*?"', f'<img id="kospi-chart" class="chart-img" src="{kospi_chart}"', content)

if sp500_val:
    content = re.sub(r'<p id="sp500-val">.*?</p>', f'<p id="sp500-val">{sp500_val:,.2f}</p>', content)
    content = re.sub(r'<img id="sp500-chart" class="chart-img" src=".*?"', f'<img id="sp500-chart" class="chart-img" src="{sp500_chart}"', content)

if usdkrw_val:
    content = re.sub(r'<p id="exchange-val">.*?</p>', f'<p id="exchange-val">{usdkrw_val:,.2f} ì›</p>', content)
    content = re.sub(r'<img id="exchange-chart" class="chart-img" src=".*?"', f'<img id="exchange-chart" class="chart-img" src="{usdkrw_chart}"', content)

# ë‰´ìŠ¤ ì„¹ì…˜ êµì²´
content = re.sub(r'(<div id="news-content">).*?(</div>)', f'\\1{news_html}\\2', content, flags=re.DOTALL)

# ì—…ë°ì´íŠ¸ ì‹œê°„
content = re.sub(r'(<span id="last-updated">).*?(</span>)', f'\\1{now}\\2', content)

with open(html_file, 'w', encoding='utf-8') as f:
    f.write(content)

print("Update Complete.")
